{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text =\"\"\"The only person for whom the house was in any way special was Arthur Dent, and that was only because it happened\n",
    "to be the one he lived in. He had lived in it for about three years, ever since he had moved out of London because it made\n",
    "him nervous and irritable. He was about thirty as well, tall, dark-haired and never quite at ease with himself. The thing\n",
    "that used to worry him most was the fact that people always used to ask him what he was looking so worried about. He worked \n",
    "in local radio which he always used to tell his friends was a lot more interesting than they probably thought. It was,\n",
    "too most of his friends worked in advertising.\"\"\"\n",
    "lower_case = text.lower()\n",
    "cleaned_text = lower_case.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "# Using word_tokenize because it's faster than split()\n",
    "tokenized_words = word_tokenize(cleaned_text, \"english\")\n",
    "\n",
    "# Removing Stop Words\n",
    "final_words = []\n",
    "for word in tokenized_words:\n",
    "    if word not in stopwords.words('english'):\n",
    "        final_words.append(word)\n",
    "\n",
    "# Lemmatization - From plural to single + Base form of a word (example better-> good)\n",
    "lemma_words = []\n",
    "for word in final_words:\n",
    "    word = WordNetLemmatizer().lemmatize(word)\n",
    "    lemma_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analyse1(sentiment_text):\n",
    "    score = SentimentIntensityAnalyzer().polarity_scores(sentiment_text)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.094, 'neu': 0.807, 'pos': 0.099, 'compound': 0.1805}\n"
     ]
    }
   ],
   "source": [
    "sentiment_analyse1(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Sentiment\n"
     ]
    }
   ],
   "source": [
    "def sentiment_analyse(sentiment_text):\n",
    "    score = SentimentIntensityAnalyzer().polarity_scores(sentiment_text)\n",
    "    if score['neg'] > score['pos']:\n",
    "        print(\"Negative Sentiment\")\n",
    "    elif score['neg'] < score['pos']:\n",
    "        print(\"Positive Sentiment\")\n",
    "    else:\n",
    "        print(\"Neutral Sentiment\")\n",
    "\n",
    "\n",
    "sentiment_analyse(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
